{"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Setting Up and Loading Sample Data","metadata":{"id":"LjvHLaFkwF-s"}},{"cell_type":"code","source":"!git clone https://github.com/ruotianluo/ImageCaptioning.pytorch","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sWCky2uAfFgk","outputId":"b787acfb-589e-4887-8a48-d2dad3c71aec","execution":{"iopub.status.busy":"2024-09-19T21:52:14.104531Z","iopub.execute_input":"2024-09-19T21:52:14.104946Z","iopub.status.idle":"2024-09-19T21:52:15.846830Z","shell.execute_reply.started":"2024-09-19T21:52:14.104905Z","shell.execute_reply":"2024-09-19T21:52:15.845808Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Cloning into 'ImageCaptioning.pytorch'...\nremote: Enumerating objects: 2299, done.\u001b[K\nremote: Counting objects: 100% (35/35), done.\u001b[K\nremote: Compressing objects: 100% (20/20), done.\u001b[K\nremote: Total 2299 (delta 14), reused 32 (delta 14), pack-reused 2264 (from 1)\u001b[K\nReceiving objects: 100% (2299/2299), 1.40 MiB | 21.70 MiB/s, done.\nResolving deltas: 100% (1615/1615), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install gdown","metadata":{"execution":{"iopub.status.busy":"2024-09-19T21:52:15.849174Z","iopub.execute_input":"2024-09-19T21:52:15.849643Z","iopub.status.idle":"2024-09-19T21:52:30.959418Z","shell.execute_reply.started":"2024-09-19T21:52:15.849585Z","shell.execute_reply":"2024-09-19T21:52:30.958392Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Collecting gdown\n  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown) (4.12.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from gdown) (3.15.1)\nRequirement already satisfied: requests[socks] in /opt/conda/lib/python3.10/site-packages (from gdown) (2.32.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from gdown) (4.66.4)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2024.7.4)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\nDownloading gdown-5.2.0-py3-none-any.whl (18 kB)\nInstalling collected packages: gdown\nSuccessfully installed gdown-5.2.0\n","output_type":"stream"}]},{"cell_type":"code","source":"!gdown https://drive.google.com/uc?id=1pSfTXtevxSh84LTsV-Ed-nolxPQBxFYQ -O /kaggle/working/ImageCaptioning.pytorch/model-best.pth","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rSp3Qs3GfbUi","outputId":"f821c217-8222-43e4-8a37-e656acb3ee29","execution":{"iopub.status.busy":"2024-09-19T21:52:30.961396Z","iopub.execute_input":"2024-09-19T21:52:30.961726Z","iopub.status.idle":"2024-09-19T21:52:37.370512Z","shell.execute_reply.started":"2024-09-19T21:52:30.961691Z","shell.execute_reply":"2024-09-19T21:52:37.369568Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Downloading...\nFrom: https://drive.google.com/uc?id=1pSfTXtevxSh84LTsV-Ed-nolxPQBxFYQ\nTo: /kaggle/working/ImageCaptioning.pytorch/model-best.pth\n100%|██████████████████████████████████████| 53.6M/53.6M [00:00<00:00, 60.8MB/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"!gdown https://drive.google.com/uc?id=1QG4criqiVuCfur6juvH1ddi2twUS3bJ9 -O /kaggle/working/ImageCaptioning.pytorch/infos_fc_nsc-best.pkl","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E3LlyIu9V1Tr","outputId":"dafeeae7-b910-46e6-cd10-ce6f7ecc0b7e","execution":{"iopub.status.busy":"2024-09-19T21:52:37.372044Z","iopub.execute_input":"2024-09-19T21:52:37.372476Z","iopub.status.idle":"2024-09-19T21:52:42.368769Z","shell.execute_reply.started":"2024-09-19T21:52:37.372422Z","shell.execute_reply":"2024-09-19T21:52:42.367642Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Downloading...\nFrom: https://drive.google.com/uc?id=1QG4criqiVuCfur6juvH1ddi2twUS3bJ9\nTo: /kaggle/working/ImageCaptioning.pytorch/infos_fc_nsc-best.pkl\n100%|██████████████████████████████████████| 1.27M/1.27M [00:00<00:00, 74.8MB/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"!cd /kaggle/working/ImageCaptioning.pytorch/data && mkdir imagenet_weights","metadata":{"execution":{"iopub.status.busy":"2024-09-19T21:54:41.247300Z","iopub.execute_input":"2024-09-19T21:54:41.248353Z","iopub.status.idle":"2024-09-19T21:54:42.252826Z","shell.execute_reply.started":"2024-09-19T21:54:41.248303Z","shell.execute_reply":"2024-09-19T21:54:42.251605Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"!cd ImageCaptioning.pytorch/data && ls","metadata":{"execution":{"iopub.status.busy":"2024-09-19T21:54:44.581643Z","iopub.execute_input":"2024-09-19T21:54:44.582533Z","iopub.status.idle":"2024-09-19T21:54:45.583539Z","shell.execute_reply.started":"2024-09-19T21:54:44.582488Z","shell.execute_reply":"2024-09-19T21:54:45.582416Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"README.md  imagenet_weights\n","output_type":"stream"}]},{"cell_type":"code","source":"!gdown https://drive.google.com/uc?id=0B7fNdx_jAqhtam1MSTNSYXVYZ2s -O /kaggle/working/ImageCaptioning.pytorch/data/imagenet_weights/resnet50.pth","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H37xpZnYhE8W","outputId":"350a0f3a-ba40-47f7-c0a1-c6914ee1bb0e","execution":{"iopub.status.busy":"2024-09-19T21:54:50.574293Z","iopub.execute_input":"2024-09-19T21:54:50.574690Z","iopub.status.idle":"2024-09-19T21:55:01.342897Z","shell.execute_reply.started":"2024-09-19T21:54:50.574654Z","shell.execute_reply":"2024-09-19T21:55:01.341894Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Downloading...\nFrom: https://drive.google.com/uc?id=0B7fNdx_jAqhtam1MSTNSYXVYZ2s\nTo: /kaggle/working/ImageCaptioning.pytorch/data/imagenet_weights/resnet50.pth\n100%|████████████████████████████████████████| 103M/103M [00:02<00:00, 38.2MB/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"!gdown https://drive.google.com/uc?id=0B7fNdx_jAqhtSmdCNDVOVVdINWs -O /kaggle/working/ImageCaptioning.pytorch/data/imagenet_weights/resnet101.pth","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cIP3zpPViVIs","outputId":"59afd483-4b22-4aa0-a202-49f20f3b9692","execution":{"iopub.status.busy":"2024-09-19T21:55:01.344791Z","iopub.execute_input":"2024-09-19T21:55:01.345172Z","iopub.status.idle":"2024-09-19T21:55:10.422948Z","shell.execute_reply.started":"2024-09-19T21:55:01.345117Z","shell.execute_reply":"2024-09-19T21:55:10.421980Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Downloading...\nFrom (original): https://drive.google.com/uc?id=0B7fNdx_jAqhtSmdCNDVOVVdINWs\nFrom (redirected): https://drive.google.com/uc?id=0B7fNdx_jAqhtSmdCNDVOVVdINWs&confirm=t&uuid=6d7248a2-9212-44fc-9bb2-b60901e84c1a\nTo: /kaggle/working/ImageCaptioning.pytorch/data/imagenet_weights/resnet101.pth\n100%|████████████████████████████████████████| 179M/179M [00:03<00:00, 47.8MB/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"!gdown https://drive.google.com/uc?id=0B7fNdx_jAqhtckNGQ2FLd25fa3c -O /kaggle/working/ImageCaptioning.pytorch/data/imagenet_weights/resnet152.pth","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OtfRtIiul7Fj","outputId":"b8b5bd9b-1d2a-4fe7-ed4b-b11cbf189e03","execution":{"iopub.status.busy":"2024-09-19T21:55:10.424431Z","iopub.execute_input":"2024-09-19T21:55:10.424816Z","iopub.status.idle":"2024-09-19T21:55:20.397305Z","shell.execute_reply.started":"2024-09-19T21:55:10.424777Z","shell.execute_reply":"2024-09-19T21:55:20.396162Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Downloading...\nFrom (original): https://drive.google.com/uc?id=0B7fNdx_jAqhtckNGQ2FLd25fa3c\nFrom (redirected): https://drive.google.com/uc?id=0B7fNdx_jAqhtckNGQ2FLd25fa3c&confirm=t&uuid=9c111318-2332-4a78-9215-2c7b31ddba87\nTo: /kaggle/working/ImageCaptioning.pytorch/data/imagenet_weights/resnet152.pth\n100%|████████████████████████████████████████| 242M/242M [00:04<00:00, 51.4MB/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"!cd ImageCaptioning.pytorch && python -m pip install -e .","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kOS87LjKoEyl","outputId":"7a0f824f-3a1e-4046-828c-334b8cdf02eb","execution":{"iopub.status.busy":"2024-09-19T21:55:24.451149Z","iopub.execute_input":"2024-09-19T21:55:24.451616Z","iopub.status.idle":"2024-09-19T21:55:40.591874Z","shell.execute_reply.started":"2024-09-19T21:55:24.451573Z","shell.execute_reply":"2024-09-19T21:55:40.590832Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Obtaining file:///kaggle/working/ImageCaptioning.pytorch\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hInstalling collected packages: captioning\n  Running setup.py develop for captioning\nSuccessfully installed captioning-0.0.1\n","output_type":"stream"}]},{"cell_type":"code","source":"import os","metadata":{"id":"XxdjMIWlpA3M","execution":{"iopub.status.busy":"2024-09-19T21:55:40.594135Z","iopub.execute_input":"2024-09-19T21:55:40.594539Z","iopub.status.idle":"2024-09-19T21:55:40.599497Z","shell.execute_reply.started":"2024-09-19T21:55:40.594493Z","shell.execute_reply":"2024-09-19T21:55:40.598517Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"!pip install shap==0.39.0","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ARHPFrZvq7la","outputId":"b5aab336-e4e4-4823-e9b6-51a1c013969d","execution":{"iopub.status.busy":"2024-09-19T21:55:51.920956Z","iopub.execute_input":"2024-09-19T21:55:51.921849Z","iopub.status.idle":"2024-09-19T21:56:11.829284Z","shell.execute_reply.started":"2024-09-19T21:55:51.921805Z","shell.execute_reply":"2024-09-19T21:56:11.828283Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Collecting shap==0.39.0\n  Downloading shap-0.39.0.tar.gz (356 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m356.2/356.2 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from shap==0.39.0) (1.26.4)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from shap==0.39.0) (1.14.0)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from shap==0.39.0) (1.2.2)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from shap==0.39.0) (2.2.2)\nRequirement already satisfied: tqdm>4.25.0 in /opt/conda/lib/python3.10/site-packages (from shap==0.39.0) (4.66.4)\nRequirement already satisfied: slicer==0.0.7 in /opt/conda/lib/python3.10/site-packages (from shap==0.39.0) (0.0.7)\nRequirement already satisfied: numba in /opt/conda/lib/python3.10/site-packages (from shap==0.39.0) (0.58.1)\nRequirement already satisfied: cloudpickle in /opt/conda/lib/python3.10/site-packages (from shap==0.39.0) (3.0.0)\nRequirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba->shap==0.39.0) (0.41.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->shap==0.39.0) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->shap==0.39.0) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->shap==0.39.0) (2024.1)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->shap==0.39.0) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->shap==0.39.0) (3.5.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->shap==0.39.0) (1.16.0)\nBuilding wheels for collected packages: shap\n  Building wheel for shap (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for shap: filename=shap-0.39.0-cp310-cp310-linux_x86_64.whl size=413724 sha256=cad19ab8627cfcf7d6f5eb061142a735e706211451ba5f9ed13fa0e28bc65835\n  Stored in directory: /root/.cache/pip/wheels/d4/ef/8d/78a07e01b86b1a0363626186f072e01683c10335e2eb89e337\nSuccessfully built shap\nInstalling collected packages: shap\n  Attempting uninstall: shap\n    Found existing installation: shap 0.44.1\n    Uninstalling shap-0.44.1:\n      Successfully uninstalled shap-0.44.1\nSuccessfully installed shap-0.39.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import shap","metadata":{"id":"maQzd_T4q-ki","execution":{"iopub.status.busy":"2024-09-19T21:56:15.488439Z","iopub.execute_input":"2024-09-19T21:56:15.488865Z","iopub.status.idle":"2024-09-19T21:56:35.227711Z","shell.execute_reply.started":"2024-09-19T21:56:15.488812Z","shell.execute_reply":"2024-09-19T21:56:35.226656Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"print(shap.__version__)","metadata":{"execution":{"iopub.status.busy":"2024-09-19T21:57:25.303915Z","iopub.execute_input":"2024-09-19T21:57:25.304587Z","iopub.status.idle":"2024-09-19T21:57:25.309158Z","shell.execute_reply.started":"2024-09-19T21:57:25.304545Z","shell.execute_reply":"2024-09-19T21:57:25.308223Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"0.39.0\n","output_type":"stream"}]},{"cell_type":"code","source":"from shap.utils.image import save_image, make_dir, add_sample_images, load_image, is_empty","metadata":{"id":"293HffnkrJO6","execution":{"iopub.status.busy":"2024-09-19T21:57:28.652928Z","iopub.execute_input":"2024-09-19T21:57:28.653351Z","iopub.status.idle":"2024-09-19T21:57:28.658936Z","shell.execute_reply.started":"2024-09-19T21:57:28.653312Z","shell.execute_reply":"2024-09-19T21:57:28.657900Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"os.chdir(\"/kaggle/working/ImageCaptioning.pytorch/\")","metadata":{"id":"zIAx182jrgYD","execution":{"iopub.status.busy":"2024-09-19T21:57:29.675038Z","iopub.execute_input":"2024-09-19T21:57:29.675462Z","iopub.status.idle":"2024-09-19T21:57:29.680030Z","shell.execute_reply.started":"2024-09-19T21:57:29.675424Z","shell.execute_reply":"2024-09-19T21:57:29.679086Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"TEST_IMAGES_DIR = \"./test_images/\"","metadata":{"id":"WXyxts3Er04S","execution":{"iopub.status.busy":"2024-09-19T21:57:30.753090Z","iopub.execute_input":"2024-09-19T21:57:30.753579Z","iopub.status.idle":"2024-09-19T21:57:30.759817Z","shell.execute_reply.started":"2024-09-19T21:57:30.753533Z","shell.execute_reply":"2024-09-19T21:57:30.758626Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# Directory for test images to be explained\nmake_dir(TEST_IMAGES_DIR)\nadd_sample_images(TEST_IMAGES_DIR)","metadata":{"id":"RF7Frl1tsKjz","execution":{"iopub.status.busy":"2024-09-19T21:57:31.615860Z","iopub.execute_input":"2024-09-19T21:57:31.616291Z","iopub.status.idle":"2024-09-19T21:57:33.155851Z","shell.execute_reply.started":"2024-09-19T21:57:31.616251Z","shell.execute_reply":"2024-09-19T21:57:33.155035Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# Directory for saving masked images\nMASKED_IMAGES_DIR = \"./masked_images/\"","metadata":{"id":"zNv2nuHssnLC","execution":{"iopub.status.busy":"2024-09-19T21:57:46.476992Z","iopub.execute_input":"2024-09-19T21:57:46.477398Z","iopub.status.idle":"2024-09-19T21:57:46.481901Z","shell.execute_reply.started":"2024-09-19T21:57:46.477362Z","shell.execute_reply":"2024-09-19T21:57:46.480843Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"!pip install git+https://github.com/ruotianluo/meshed-memory-transformer.git","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0q-B640duLKN","outputId":"90c10f99-e893-43df-c42a-7527f4a1418e","execution":{"iopub.status.busy":"2024-09-19T21:57:51.337790Z","iopub.execute_input":"2024-09-19T21:57:51.338155Z","iopub.status.idle":"2024-09-19T21:58:07.631874Z","shell.execute_reply.started":"2024-09-19T21:57:51.338119Z","shell.execute_reply":"2024-09-19T21:58:07.630690Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stderr","text":"os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","output_type":"stream"},{"name":"stdout","text":"Collecting git+https://github.com/ruotianluo/meshed-memory-transformer.git\n  Cloning https://github.com/ruotianluo/meshed-memory-transformer.git to /tmp/pip-req-build-_s3mq9yn\n  Running command git clone --filter=blob:none --quiet https://github.com/ruotianluo/meshed-memory-transformer.git /tmp/pip-req-build-_s3mq9yn\n  Resolved https://github.com/ruotianluo/meshed-memory-transformer.git to commit f74657320a947ad1d9868de6a6c757dbac341eda\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hBuilding wheels for collected packages: meshed_memory_transformer\n  Building wheel for meshed_memory_transformer (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for meshed_memory_transformer: filename=meshed_memory_transformer-0.0.1-py3-none-any.whl size=39518 sha256=76aec28ac624f597eb6f806df85e99bf4cb1230c609ddd4b37d5d8b6e6c16520\n  Stored in directory: /tmp/pip-ephem-wheel-cache-_c7fil6k/wheels/98/10/2e/74211626a660b85e2332e7884db384c5aca1894d57fb1eddc2\nSuccessfully built meshed_memory_transformer\nInstalling collected packages: meshed_memory_transformer\nSuccessfully installed meshed_memory_transformer-0.0.1\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install lmdbdict","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oEDY0cDWugp1","outputId":"f298200b-76bd-426c-a113-c1007ea7c1fe","execution":{"iopub.status.busy":"2024-09-19T21:58:07.634014Z","iopub.execute_input":"2024-09-19T21:58:07.634449Z","iopub.status.idle":"2024-09-19T21:58:21.282895Z","shell.execute_reply.started":"2024-09-19T21:58:07.634412Z","shell.execute_reply":"2024-09-19T21:58:21.281693Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"Collecting lmdbdict\n  Downloading lmdbdict-0.2.2-py3-none-any.whl.metadata (225 bytes)\nCollecting lmdb (from lmdbdict)\n  Downloading lmdb-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\nDownloading lmdbdict-0.2.2-py3-none-any.whl (6.0 kB)\nDownloading lmdb-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (294 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: lmdb, lmdbdict\nSuccessfully installed lmdb-1.5.1 lmdbdict-0.2.2\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install pycocotools","metadata":{"execution":{"iopub.status.busy":"2024-09-19T21:58:21.284462Z","iopub.execute_input":"2024-09-19T21:58:21.284849Z","iopub.status.idle":"2024-09-19T21:58:34.710455Z","shell.execute_reply.started":"2024-09-19T21:58:21.284807Z","shell.execute_reply":"2024-09-19T21:58:34.709407Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"Collecting pycocotools\n  Downloading pycocotools-2.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\nRequirement already satisfied: matplotlib>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from pycocotools) (3.7.5)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from pycocotools) (1.26.4)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (1.2.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (4.53.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (21.3)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (9.5.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (2.9.0.post0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools) (1.16.0)\nDownloading pycocotools-2.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (427 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m427.8/427.8 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pycocotools\nSuccessfully installed pycocotools-2.0.8\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install pycocoevalcap","metadata":{"execution":{"iopub.status.busy":"2024-09-19T21:59:06.719190Z","iopub.execute_input":"2024-09-19T21:59:06.719588Z","iopub.status.idle":"2024-09-19T21:59:21.818252Z","shell.execute_reply.started":"2024-09-19T21:59:06.719549Z","shell.execute_reply":"2024-09-19T21:59:21.817168Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stderr","text":"os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","output_type":"stream"},{"name":"stdout","text":"Collecting pycocoevalcap\n  Downloading pycocoevalcap-1.2-py3-none-any.whl.metadata (3.2 kB)\nRequirement already satisfied: pycocotools>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from pycocoevalcap) (2.0.8)\nRequirement already satisfied: matplotlib>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from pycocotools>=2.0.2->pycocoevalcap) (3.7.5)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from pycocotools>=2.0.2->pycocoevalcap) (1.26.4)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap) (1.2.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap) (4.53.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap) (21.3)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap) (9.5.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap) (2.9.0.post0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap) (1.16.0)\nDownloading pycocoevalcap-1.2-py3-none-any.whl (104.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.3/104.3 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pycocoevalcap\nSuccessfully installed pycocoevalcap-1.2\n","output_type":"stream"}]},{"cell_type":"code","source":"import gc\nimport sys\n\n# to suppress verbose output from open source model\nfrom contextlib import contextmanager\n\nimport captioning.models as models\nimport captioning.modules.losses as losses\nimport captioning.utils.eval_utils as eval_utils\nimport captioning.utils.misc as utils\nimport numpy as np\nimport torch\nfrom captioning.data.dataloader import DataLoader\nfrom captioning.data.dataloaderraw import DataLoaderRaw\nfrom transformers import AutoModelForSeq2SeqLM, AutoTokenizer","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kdm9pNEZtbjP","outputId":"c3c2428a-621d-4691-b49e-c0f30a79c311","execution":{"iopub.status.busy":"2024-09-19T21:59:23.422725Z","iopub.execute_input":"2024-09-19T21:59:23.423171Z","iopub.status.idle":"2024-09-19T21:59:23.431082Z","shell.execute_reply.started":"2024-09-19T21:59:23.423128Z","shell.execute_reply":"2024-09-19T21:59:23.429971Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"@contextmanager\ndef suppress_stdout():\n    with open(os.devnull, \"w\") as devnull:\n        old_stdout = sys.stdout\n        sys.stdout = devnull\n        old_stderr = sys.stderr\n        sys.stderr = devnull\n        try:\n            yield\n        finally:\n            sys.stdout = old_stdout\n            sys.stderr = old_stderr","metadata":{"id":"WA7y_R6AuCCy","execution":{"iopub.status.busy":"2024-09-19T21:59:27.919897Z","iopub.execute_input":"2024-09-19T21:59:27.920578Z","iopub.status.idle":"2024-09-19T21:59:27.925931Z","shell.execute_reply.started":"2024-09-19T21:59:27.920533Z","shell.execute_reply":"2024-09-19T21:59:27.925064Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":"## Getting Captions","metadata":{"id":"n9O8wgUYwdnC"}},{"cell_type":"code","source":"class ImageCaptioningModel:\n    def __init__(self, model_path, infos_path, cnn_model=\"resnet101\", device=\"cuda\"):\n        \"\"\"Initializing the class by loading torch model and vocabulary at path given and using Resnet weights stored in data/imagenet_weights.\n        This is done to speeden the process of getting image captions and avoid loading the model every time captions are needed.\n\n        Parameters\n        ----------\n        model_path  : pre-trained model path\n        infos_path  : pre-trained infos (vocab) path\n        cnn_model   : resnet model weights to use; options: \"resnet101\" (default), \"resnet152\"\n        device      : \"cpu\" or \"cuda\" (default)\n\n        \"\"\"\n        # load infos\n        with open(infos_path, \"rb\") as f:\n            infos = utils.pickle_load(f)\n        opt = infos[\"opt\"]\n\n        # setup the model\n        opt.model = model_path\n        opt.cnn_model = cnn_model\n        opt.device = device\n        opt.vocab = infos[\"vocab\"]  # index -> word mapping\n        model = models.setup(opt)\n        del infos\n        del opt.vocab\n        model.load_state_dict(torch.load(opt.model, map_location=\"cpu\"))\n        model.to(opt.device)\n        model.eval()\n        loss = losses.LanguageModelCriterion()\n\n        # setup class variables for call function\n        self.opt = opt\n        self.model = model\n        self.loss = loss\n        self.infos_path = infos_path\n\n        # free memory\n        torch.cuda.empty_cache()\n        gc.collect()\n\n    def __call__(self, image_folder, batch_size):\n        \"\"\"Function to get captions for images placed in image_folder.\n\n        Parameters\n        ----------\n        image_folder: folder of images for which captions are needed\n        batch_size  : number of images to be evaluated at once\n        Output\n        -------\n        captions    : list of captions for images in image_folder (will return a string if there is only one image in folder)\n\n        \"\"\"\n        # setting eval options\n        opt = self.opt\n        opt.batch_size = batch_size\n        opt.image_folder = image_folder\n        opt.coco_json = \"\"\n        opt.dataset = opt.input_json\n        opt.verbose_loss = 0\n        opt.verbose = False\n        opt.dump_path = 0\n        opt.dump_images = 0\n        opt.num_images = -1\n        opt.language_eval = 0\n\n        # loading vocab\n        with open(self.infos_path, \"rb\") as f:\n            infos = utils.pickle_load(f)\n        opt.vocab = infos[\"vocab\"]\n\n        # creating Data Loader instance to load images\n        if len(opt.image_folder) == 0:\n            loader = DataLoader(opt)\n        else:\n            loader = DataLoaderRaw(\n                {\n                    \"folder_path\": opt.image_folder,\n                    \"coco_json\": opt.coco_json,\n                    \"batch_size\": opt.batch_size,\n                    \"cnn_model\": opt.cnn_model,\n                }\n            )\n\n        # when evaluating using provided pretrained model, vocab may be different from what is in cocotalk.json.\n        # hence, setting vocab from infos file.\n        loader.dataset.ix_to_word = opt.vocab\n        del infos\n        del opt.vocab\n\n        # getting caption predictions\n        _, split_predictions, _ = eval_utils.eval_split(self.model, self.loss, loader, vars(opt))\n        captions = []\n        for line in split_predictions:\n            captions.append(line[\"caption\"])\n\n        # free memory\n        del loader\n        torch.cuda.empty_cache()\n        gc.collect()\n\n        return captions if len(captions) > 1 else captions[0]","metadata":{"id":"sj39W76IwBoA","execution":{"iopub.status.busy":"2024-09-19T21:59:36.531724Z","iopub.execute_input":"2024-09-19T21:59:36.532806Z","iopub.status.idle":"2024-09-19T21:59:36.548934Z","shell.execute_reply.started":"2024-09-19T21:59:36.532751Z","shell.execute_reply":"2024-09-19T21:59:36.548018Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"# create instance of ImageCaptioningModel\nosmodel = ImageCaptioningModel(\n    model_path=\"model-best.pth\",\n    infos_path=\"infos_fc_nsc-best.pkl\",\n    cnn_model=\"resnet101\",\n    device=\"cpu\",\n)\n\n\n# create function to get caption using model created above\ndef get_caption(model, image_folder, batch_size):\n    return model(image_folder, batch_size)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hIqWrlmk4t64","outputId":"1aa5ffc0-7fe3-4b2d-e2cb-28e021e4bc8f","execution":{"iopub.status.busy":"2024-09-19T21:59:46.255277Z","iopub.execute_input":"2024-09-19T21:59:46.255722Z","iopub.status.idle":"2024-09-19T21:59:46.959242Z","shell.execute_reply.started":"2024-09-19T21:59:46.255663Z","shell.execute_reply":"2024-09-19T21:59:46.958300Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stderr","text":"You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","output_type":"stream"}]},{"cell_type":"code","source":"# checks if test images folder exists and if it has any files\nif not is_empty(TEST_IMAGES_DIR):\n    X = []\n    print(\"Loading data...\")\n    files = [f for f in os.listdir(TEST_IMAGES_DIR) if os.path.isfile(os.path.join(TEST_IMAGES_DIR, f))]\n    for file in files:\n        path_to_image = os.path.join(TEST_IMAGES_DIR, file)\n        print(\"Loading image:\", file)\n        X.append(load_image(path_to_image))\n    with suppress_stdout():\n        captions = get_caption(osmodel, \"test_images\", 5)\n    if len(X) > 1:\n        print(\"\\nCaptions are...\", *captions, sep=\"\\n\")\n    else:\n        print(\"\\nCaption is...\", captions)\n    print(\"\\nNumber of images in test dataset:\", len(X))","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":460},"id":"tCJegdJ05Um6","outputId":"11bfb688-7f17-4a30-dc0a-ef6fcdf0b100","execution":{"iopub.status.busy":"2024-09-19T21:59:49.099488Z","iopub.execute_input":"2024-09-19T21:59:49.099871Z","iopub.status.idle":"2024-09-19T21:59:52.118642Z","shell.execute_reply.started":"2024-09-19T21:59:49.099834Z","shell.execute_reply":"2024-09-19T21:59:52.117707Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"Loading data...\nLoading image: 3.jpg\nLoading image: 2.jpg\nLoading image: 4.jpg\nLoading image: 1.jpg\n\nCaptions are...\na group of horses standing next to a fence\na bird sitting on top of a tree branch\na group of people playing with a soccer ball\na woman sitting on a bench\n\nNumber of images in test dataset: 4\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Using Distilbart as the language model and tokenizer","metadata":{"id":"qCWStUdc8Ikk"}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"sshleifer/distilbart-xsum-12-6\")\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"sshleifer/distilbart-xsum-12-6\").cuda()","metadata":{"id":"4H0zqZ4Y6QKS","execution":{"iopub.status.busy":"2024-09-19T21:59:55.866916Z","iopub.execute_input":"2024-09-19T21:59:55.867332Z","iopub.status.idle":"2024-09-19T22:00:01.626995Z","shell.execute_reply.started":"2024-09-19T21:59:55.867291Z","shell.execute_reply":"2024-09-19T22:00:01.626016Z"},"trusted":true},"execution_count":43,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87b801a5c0424adf8866825e1606215e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.59k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"19370d53f2e24f28af97a20b33e2aead"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a49b68d4a200498fb1b1304dd09fad62"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b7175b6ca68b46d7870b7425d92dd2a2"}},"metadata":{}},{"name":"stderr","text":"`clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/611M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8889e06a311e4c4999017818ce9f1100"}},"metadata":{}}]},{"cell_type":"markdown","source":"## Creating an Explainable Object","metadata":{}},{"cell_type":"code","source":"# setting values for logging/tracking variables\nmake_dir(MASKED_IMAGES_DIR)\nimage_counter = 0\nmask_counter = 0\n\n\n# define function f which takes input (masked image) and returns caption for it\ndef f(x):\n    global mask_counter\n\n    # emptying masked images directory\n    make_dir(MASKED_IMAGES_DIR)\n\n    # saving masked array of RGB values as an image in masked_images directory\n    path_to_image = os.path.join(MASKED_IMAGES_DIR, f\"{image_counter}_{mask_counter}.png\")\n    save_image(x, path_to_image)\n\n    # getting caption of masked image\n    with suppress_stdout():\n        caption = get_caption(osmodel, \"masked_images\", 50)\n    mask_counter += 1\n\n    return caption\n\n\n# function to take a list of images and parameters such as masking option, max evals etc. and return shap_values_objects\ndef run_masker(X, mask_value=\"inpaint_ns\", max_evals=300, batch_size=50, fixed_context=None):\n    \"\"\"Function to take a list of images and parameters such max evals etc. and return shap explanations (shap_values) for test images(X).\n    Paramaters\n    ----------\n    X               : list of images which need to be explained\n    mask_value      : various masking options for blurring/inpainting such as \"inpaint_ns\", \"inpaint_telea\" and \"blur(pixel_size, pixel_size)\"\n    max_evals       : number of evaluations done of the underlying model to get SHAP values\n    batch_size      : number of masked images to be evaluated at once\n    fixed_context   : masking technqiue used to build partition tree with options of '0', '1' or 'None'\n    Output\n    ------\n    shap_values_list: list of shap_values objects generated for the images\n    \"\"\"\n    global image_counter\n    global mask_counter\n    shap_values_list = []\n    \n    for index in range(len(X)):\n        # define a masker that is used to mask out partitions of the input image based on mask_value option\n        masker = shap.maskers.Image(mask_value, X[index].shape)\n        \n        # wrap model with TeacherForcing class\n        wrapped_model = shap.models.TeacherForcing(f, similarity_model=model, similarity_tokenizer=tokenizer)\n\n        # build a partition explainer with wrapped_model and image masker\n        explainer = shap.Explainer(wrapped_model, masker)\n\n        # compute SHAP values - here we use max_evals no. of evaluations of the underlying model to estimate SHAP values\n        shap_values = explainer(\n            np.array(X[index : index + 1]),\n            max_evals=max_evals,\n            batch_size=batch_size,\n            fixed_context=fixed_context,\n        )\n        shap_values_list.append(shap_values)\n        # output plot\n        shap_values.output_names[0] = [word.replace(\"Ġ\", \"\") for word in shap_values.output_names[0]]\n        shap.image_plot(shap_values)\n\n        # setting values for next iterations\n        mask_counter = 0\n        image_counter += 1\n\n    return shap_values_list","metadata":{"id":"oVJY2tA3-ec6","execution":{"iopub.status.busy":"2024-09-19T22:00:03.911606Z","iopub.execute_input":"2024-09-19T22:00:03.912001Z","iopub.status.idle":"2024-09-19T22:00:03.924294Z","shell.execute_reply.started":"2024-09-19T22:00:03.911961Z","shell.execute_reply":"2024-09-19T22:00:03.923162Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"!apt-get install python3.9","metadata":{"execution":{"iopub.status.busy":"2024-09-19T22:11:18.299772Z","iopub.execute_input":"2024-09-19T22:11:18.300736Z","iopub.status.idle":"2024-09-19T22:11:23.914753Z","shell.execute_reply.started":"2024-09-19T22:11:18.300688Z","shell.execute_reply":"2024-09-19T22:11:23.913628Z"},"trusted":true},"execution_count":59,"outputs":[{"name":"stdout","text":"Reading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\nNote, selecting 'python3.9-llfuse' for regex 'python3.9'\nNote, selecting 'python3-llfuse' instead of 'python3.9-llfuse'\nSuggested packages:\n  python-llfuse-doc\nThe following NEW packages will be installed:\n  python3-llfuse\n0 upgraded, 1 newly installed, 0 to remove and 39 not upgraded.\nNeed to get 291 kB of archives.\nAfter this operation, 1205 kB of additional disk space will be used.\nGet:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 python3-llfuse amd64 1.3.8+dfsg-2build1 [291 kB]\nFetched 291 kB in 0s (633 kB/s)        \nSelecting previously unselected package python3-llfuse:amd64.\n(Reading database ... 123110 files and directories currently installed.)\nPreparing to unpack .../python3-llfuse_1.3.8+dfsg-2build1_amd64.deb ...\nUnpacking python3-llfuse:amd64 (1.3.8+dfsg-2build1) ...\nSetting up python3-llfuse:amd64 (1.3.8+dfsg-2build1) ...\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## SHAP Explanation for Test Images","metadata":{}},{"cell_type":"code","source":"# SHAP explanation using masking option \"blur(pixel_size, pixel_size)\" for blurring\nshap_values = run_masker(X, mask_value=\"blur(56,56)\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SHAP explanation using masking option \"blur(pixel_size, pixel_size)\" for blurring\nshap_values = run_masker(X, mask_value=\"blur(56,56)\")","metadata":{},"execution_count":null,"outputs":[]}]}